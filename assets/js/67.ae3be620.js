(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{504:function(s,t,a){"use strict";a.r(t);var n=a(11),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"字典"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#字典"}},[s._v("#")]),s._v(" 字典")]),s._v(" "),a("blockquote",[a("p",[s._v("字典，又称符号表，关联数组或者映射，是一种用于保存键值对的抽象数据结构。")]),s._v(" "),a("p",[s._v("字典中的每个键都是唯一的，值可以不同")])]),s._v(" "),a("h2",{attrs:{id:"_1-字典的实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-字典的实现"}},[s._v("#")]),s._v(" 1. 字典的实现")]),s._v(" "),a("h3",{attrs:{id:"_1-1-哈希表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-哈希表"}},[s._v("#")]),s._v(" 1.1 哈希表")]),s._v(" "),a("blockquote",[a("p",[s._v("哈希表是根据关键码的值而直接进行访问的数据结构")])]),s._v(" "),a("p",[a("strong",[s._v("结构定义")])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n * dict.h/dictht\n * 哈希表\n * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。\n */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictht")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 哈希表数组")]),s._v("\n    dictEntry "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 哈希表大小")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 哈希表大小掩码，用于计算索引值")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 总是等于 size - 1")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" sizemask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 该哈希表已有节点的数量")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" used"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dictht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("ul",[a("li",[a("strong",[s._v("table")]),s._v("：表示一个数组，每个元素都指向dictEntry结构的指针，每个dictEntry结构保存着一个键值对")]),s._v(" "),a("li",[a("strong",[s._v("size")]),s._v("：表示哈希表的大小(dictEntry)")]),s._v(" "),a("li",[a("strong",[s._v("used")]),s._v("：表示哈希表当前已有的节点数量")]),s._v(" "),a("li",[a("strong",[s._v("sizemask")]),s._v("：总是等于size - 1， 它和哈希值一起决定一个键应该被放到table数组的哪个索引上面")])]),s._v(" "),a("h3",{attrs:{id:"_1-2-哈希表节点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-哈希表节点"}},[s._v("#")]),s._v(" 1.2 哈希表节点")]),s._v(" "),a("p",[a("strong",[s._v("结构定义")])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n * 哈希表节点\n */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictEntry")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 键")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 值")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("union")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("uint64_t")]),s._v(" u64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("int64_t")]),s._v(" s64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 指向下个哈希表节点，形成链表")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictEntry")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("next"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dictEntry"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br")])]),a("ul",[a("li",[a("strong",[s._v("key")]),s._v("：保存着键值对中的键")]),s._v(" "),a("li",[a("strong",[s._v("v")]),s._v("：保存着键值对中的值，可以是一个指针、uint64_t整数或者int64_t整数")]),s._v(" "),a("li",[a("strong",[s._v("next")]),s._v("：指向另一个哈希表节点的指针，构成一个单链表，以此来解决哈希冲突(collsion)问题")])]),s._v(" "),a("h3",{attrs:{id:"_1-3-字典"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-字典"}},[s._v("#")]),s._v(" 1.3 字典")]),s._v(" "),a("p",[a("strong",[s._v("结构定义")])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n * 字典\n */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dict")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 类型特定函数")]),s._v("\n    dictType "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 私有数据")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 哈希表")]),s._v("\n    dictht ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// rehash 索引")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 当 rehash 不在进行时，值为 -1")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" rehashidx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* rehashing not in progress if rehashidx == -1 */")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 目前正在运行的安全迭代器的数量")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" iterators"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* number of iterators currently running */")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("blockquote",[a("p",[s._v("type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的。")])]),s._v(" "),a("ul",[a("li",[a("p",[a("strong",[s._v("type")]),s._v("：指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字段设置不同的类型特定函数。")])]),s._v(" "),a("li",[a("p",[a("strong",[s._v("privdata")]),s._v("：保存了需要传给那些类型特定函数的可选参数。")])])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n * 字典类型特定函数\n */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictType")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 计算哈希值的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("hashFunction"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 复制键的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("keyDup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 复制值的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("valDup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 对比键的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("keyCompare"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 销毁键的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("keyDestructor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 销毁值的函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("valDestructor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dictType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br")])]),a("ul",[a("li",[a("strong",[s._v("ht")]),s._v("：是一个包含两个项的数组，数组中每一项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]进行rehash时使用。")]),s._v(" "),a("li",[a("strong",[s._v("rehashidx")]),s._v("：它记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1。")])]),s._v(" "),a("h2",{attrs:{id:"_2-哈希算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-哈希算法"}},[s._v("#")]),s._v(" 2. 哈希算法")]),s._v(" "),a("blockquote",[a("p",[s._v("当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面")])]),s._v(" "),a("p",[a("strong",[s._v("计算哈希值和索引值")])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 使用字典设置的哈希函数，计算键key的哈希值")]),s._v("\nhash "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" dict"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("type"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashFunction")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 根据哈希表的sizemask属性和哈希值，计算出索引值")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 根据情况不用，ht[x]可以是h[0]或者h[1]")]),s._v("\nindex "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" hash "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" dict"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("sizemask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 放入dictEntry数组index位置上")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[a("em",[s._v("MurmurHash算法最初由Austin Appleby于2008年发明，这种算法的有点在于，即使输入的键是有规律的，算法仍能给出一个很好的随机分布性，并且算法的计算速度也非常快。")])]),s._v(" "),a("p",[a("a",{attrs:{href:"http://code.google.com/p/smhasher",target:"_blank",rel:"noopener noreferrer"}},[s._v("参考算法的主页"),a("OutboundLink")],1)]),s._v(" "),a("h2",{attrs:{id:"_3-解决键冲突"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-解决键冲突"}},[s._v("#")]),s._v(" 3. 解决键冲突")]),s._v(" "),a("blockquote",[a("p",[s._v("当有两个或者以上数量的键被分配到了哈希表数组的同一个索引上，我们称这些键发生了冲突(collision)")])]),s._v(" "),a("p",[s._v("Redis的哈希表使用链地址发来解决冲突，每个哈希表节点都有一个next指针，多个节点可以用next指针构成一个单链表。由于dictEntry节点组成的链表没有指向链表"),a("strong",[s._v("尾部")]),s._v("的指针，所以Redis采用"),a("strong",[s._v("头插法")]),s._v("来插入节点。")]),s._v(" "),a("h2",{attrs:{id:"_4-rehash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-rehash"}},[s._v("#")]),s._v(" 4. rehash")]),s._v(" "),a("blockquote",[a("p",[s._v("随着操作的不断执行，哈希表保存的键值对会逐渐地增多或减少，为了让哈希表的负载因子(load factor)维持在一个合理的范围区间，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。")])]),s._v(" "),a("h3",{attrs:{id:"_4-1-rehash的步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-rehash的步骤"}},[s._v("#")]),s._v(" 4. 1 rehash的步骤")]),s._v(" "),a("p",[a("strong",[s._v("1.")]),s._v("  为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量(也即是ht[0].used属性的值)：")]),s._v(" "),a("ul",[a("li",[s._v("如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2^n。")]),s._v(" "),a("li",[s._v("如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2^n。")])]),s._v(" "),a("p",[a("strong",[s._v("2.")]),s._v(" 将保存在ht[0]中的所有键值对对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。")]),s._v(" "),a("p",[a("strong",[s._v("3.")]),s._v(" 将ht[0]包含的所有键值对都迁移到ht[1]之后(ht[0]变为空表)，释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。")]),s._v(" "),a("p",[a("strong",[s._v("举例：")])]),s._v(" "),a("ol",[a("li",[s._v("假设ht[0].used当前的值为4，4 * 2 =  8 = 2^3， 8恰好是第一个大于等于4的2的n次方，所以程序会将ht[1]哈希表的size设置为8。")]),s._v(" "),a("li",[s._v("将ht[0]上的所有键值对都rehash到ht[1]上。")]),s._v(" "),a("li",[s._v("释放ht[0]， 并将ht[1]设置为ht[0]，然后为ht[1]分配一个空白的哈希表")])]),s._v(" "),a("h3",{attrs:{id:"_4-2-哈希表的扩展与收缩"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-哈希表的扩展与收缩"}},[s._v("#")]),s._v(" 4.2 哈希表的扩展与收缩")]),s._v(" "),a("p",[a("strong",[s._v("当满足下列条件中的任意一个，程序会自动开始对哈希表执行扩展操作：")])]),s._v(" "),a("p",[a("strong",[s._v("1.")]),s._v(" 服务器目前没有执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子>=1。")]),s._v(" "),a("p",[a("strong",[s._v("2.")]),s._v(" 服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子>=5。")]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 负载因子 = 哈希表已保存节点数量 / 哈希表大小")]),s._v("\nload_factor "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("used "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("根据是否正在执行BGSAVE和BGREWRITEAOF命令，服务器执行扩展操作所需的负载因子并不相同，这是因为在执行BGSAVE或者BGREWRITEAOF的过程中，Redis需要创建当前服务器进程的子进程，而大多操作系统都采用写实复制技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免子进程存在期间进行哈希表扩展操作，这样可以避免不必要的内存写入操作，最大限度地节约内存。")]),s._v(" "),a("p",[a("strong",[s._v("当负载因子小于0.1时，程序会自动对哈希表执行收缩操作")])]),s._v(" "),a("h2",{attrs:{id:"_5-渐进式rehash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-渐进式rehash"}},[s._v("#")]),s._v(" 5. 渐进式rehash")]),s._v(" "),a("blockquote",[a("p",[s._v("在rehash的过程中，扩展和收缩哈希表需要将ht[0]里面所有的键值对rehash到ht[1]中，但是这些操作并不是一次性，集中式地完成，而是分多次、渐进式地完成。")])]),s._v(" "),a("p",[a("strong",[s._v("原因")]),s._v("：如果ht[0]中的键值对很少的话服务器就可以很快完成rehash操作，但是如果哈希表中保存的键值对数量很大(千万级、亿级)的情况下面，那么要一次性将这些键值对全部rehash到h[1]的话，巨大的计算量可能会导致服务器在一段时间内停止服务。")]),s._v(" "),a("p",[a("strong",[s._v("渐进式rehash的步骤")])]),s._v(" "),a("p",[a("strong",[s._v("1.")]),s._v(" 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。")]),s._v(" "),a("p",[a("strong",[s._v("2.")]),s._v(" 在字典中设置索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。")]),s._v(" "),a("p",[a("strong",[s._v("3.")]),s._v(" 在rehash期间，每次对字典执行正删改查的操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]上，当rehash工作完成之后，程序将rehashidx属性的值+1。")]),s._v(" "),a("p",[a("strong",[s._v("4.")]),s._v(" 随着字典操作的不断进行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设置为-1，表示rehash已经完成。")]),s._v(" "),a("p",[a("em",[s._v("渐进式rehash采用分而治之的方式，将rehash所需的计算工作均摊到对字典的每个增删改查的操作上，从而避免了集中式rehash而来带的庞大计算量。")])]),s._v(" "),a("p",[a("strong",[s._v("渐进式rehash执行期间的哈希表操作")])]),s._v(" "),a("ul",[a("li",[s._v("在渐进式rehash过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以字典的删除(delete)、查找(find)、更新(update)等操作会在两个哈希表上进行。")]),s._v(" "),a("li",[s._v("在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量只会减少不会增加，并随着rehash操作的执行而最终变成空表。")])])])}),[],!1,null,null,null);t.default=e.exports}}]);